# Deep-Generalization-based-on-Types

Note: Read tbr_paper_B659.pdf for more details.

- Explainable AI concerns giving reasons for the choices made by an AI system. Many ways has been explored ranging from using externel tools for generating explanations to modifying the architecture of a classification or a regression model to account for interpretability. 
- Sometime the efforts to improve interpretability has caused negative impact on the accuracy of the predictions. 
- In this paper, we discuss a more natural way of generating explanations. We follow the path of strong AI to build a system that think and reason like humans. 
- The system builds a knowledge graph based on observations and it uses type abstraction to make inferences. 
- The observations contains partial information like any real world data instance would. The AI system makes type inferences to fill those gaps if and when avail-able and enrich the knowledge graph.
- The system also generates explanations to reason about the inferences it made. The explanations generated by the system aligns with how a human would reason about his choices.
